---
title: "Implicit Timecourse Project"
output:
  word_document:
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: 2
    number_sections: yes
    theme: united
  pdf_document:
    toc: yes
    toc_depth: '2'
    number_sections: yes
---

# Pre-amble

In this project we set out to characterize the speed of implicit adaptation under various circumstances. There are 4 experiments.

  1. Size of rotation + washout
  2. Feedback that is supposed to increase explicit adaptation (cursor-jump, terminal)
  3. Delays, before or after terminal feedback (before should be more explicit)
  4. A comparison with the time-course of re-aiming responses

In all conditions, 4 reach training targets were used, and after each training trial (with feedback) a no-cursor trial was completed. For these trials, participants were instructed to just move their hand straight to the target, regardless of how the cursor moved. After a brief familiarization task, participants did a 20+20 trial baseline, and a 100+100 trial adaptation phase. In the first experiment, this was followed by a 24+24 trial washout phase. In most conditions, there were 8 re-aiming responses given before the 57th, 61st, 65th, 69th, 73rd, 77th, 81st and 85th rotated reach training trial. Except for the very last condition, where every reach training trial was preceded by a re-aiming response. (These were given by orienting an arrow in the screen, with 1 degree precision.)

In none of the paradigms were participants required to put the cursor on top of the target: as soon as the cursor was far enough away from the home position, the outward movement was considered finished. They did receive feedback on whether or not they were "close enough" to the target, both by colro changes of the cursor and in the form of points when they were close enough. For both the no-cursor and reach training trials, the same feedback is provided to allow returning to the start point without giving position feedback: a circle, centered on the home position, with radius equal to the distance between where the cursor would be and the home position.

Using the no-cursor reach aftereffects after every reach training trial, we can map out the speed of implicit adaptation with high temporal precision. The conditions are all supposed to evoke larger explicit strategies (or just overall adaptation, in the first experiment with rotation sizes). The re-aiming responses assess the magnitude of this strategy in each participant, such that we can also see if increased explicit strategies go hand in hand with decreased implicit adaptation (or vice versa) or whether or not these two kinds of adaptation are largely independent. Except for the last condition, we can't (and don't need to) assess the speed of explicit adaptation.

## Setting up R session

This chunk might help solve some issues with `renv`:

```{r eval=F}
unloadNamespace('renv')
install.packages('renv', version="1.0.3")
loadNamespace('renv')

renv::activate()
```

You will want to `restore()` the `renv` as used while doing this project. This should install a lot of packages so this might take a while.

```{r eval=F}
renv::restore()
```

Install the most recent Reach package (can't be handled by renv):

```{r}
library('remotes')
ip <- installed.packages()
if ('Reach' %in% ip[,'Package']) {
  if (ip[which(ip[,'Package'] == 'Reach'),'Version'] < "2023.12.17") {
    remotes::install_github('thartbm/Reach')
  }
} else {
  remotes::install_github('thartbm/Reach')
}
```

The project was done with Reach version="2023.12.17" but I don't know how to do proper versioning yet.

We load all the code for this project:

```{r echo=F, results='hide', quietly=T, warn.conflicts=F}
source('R/data.R')
source('R/utilities.R')
source('R/figures.R')
source('R/statistics.R')
source('R/exponentials.R')
```

## Data

Before doing anything, we need to get the data on the local machine.

```{r eval=FALSE}
# download the raw data AND the processed data:
downloadData()
```

This downloads the relevant data from the associated [OSF repository](https://osf.io/ajwyr/).

## Processing

If we'd also want to redo all the processing, we could run the code in this cell:

```{r eval=FALSE}
# this summarizes each reach or re-aiming response to an angular deviation relative to the target
extractAngularDeviations()
```

For all reaches, this extracts the reach deviations at 0.2 times the home-target distance (i.e. 2 cm of a 10 cm reaching movement). And for aiming responses the aiming deviation from the target. The code to do so is provided, so if you think it should be done a different (and obviously better) way, the code can be changed / replaced.

You could even redo the bootstrapping of all the exponential fit parameters, even though it would take a long time. If you changed the way the dependent variables are calculated, this step can not be skipped though, as most of the statistics / conclusion depend on the bootstrapped exponential fits.

By default, this code uses 75% of available cores (the parallelization is meant to work on Linux and MacOS as well as on Windows) and does 5000 bootstraps for each fit. This could also be changed but it's not an easy, single function argument.

```{r eval=FALSE}
# these are sorted by how much time they take: most time at the top
bootstrapAllLearningExpFits()
bootstrapAllWashoutExpFits()
bootstrapAllAimingExpFits()
groupAvgFits()
```

The above three chunks of code have been set to not evaluate, but they can be run manually in the notebook.

The total number of participants in the dataset is 458:

```{r}
knitr::kable(demographicsTable(exp=0, mergeControls=FALSE, onlyLearners=FALSE))
```

But we only use 347 participants who learned at least 50% of the rotation:

```{r}
knitr::kable(demographicsTable(exp=0, mergeControls=FALSE, onlyLearners=TRUE))
```


# Experiment 1: rotation size

In the first part we gauge our method of interleaved no-cursor trials to see how this responds to 4 different rotation sizes (15, 30, 45, and 60 degree rotations). We don't find anything surprising. 

Here is a table about the sample of participants:

```{r}
knitr::kable(demographicsTable(exp=1))
```


Here is the plot of the data.

```{r fig.width=6, fig.height=9}
expBehaviorFig(exp=1, target='inline', timecoursemode = 'absolute')
```

The table below lists group average estimates as well as bootstrapped 95% confidence intervals for several descriptors of behavior. The first 4 columns show parameters of exponential fits, for training reaches as well as no-cursor reaches. The first value is the optimal parameter for the average of the group data, the two values in parantheses are the 2.5% and 97.5% percentiles over 5k bootstraps (the 95% confidence interval). Then there are the re-aiming responses, which are simply the average and the upper and lower limit of a bootstrapped 95% confidence interval (1k values). The last two columns show exponential fits on the washout data, similar to the first 4 columns, but for simplicity we only show the starting points (here "asymptotes", need to re-label this in the paper) as the rates of changes are all very high (> 90%) and don't appear to be interesting.

```{r}
knitr::kable(expTable(exp=1))
```

## First impression of figure and table

First, we it seems that with the two smaller rotations the rate of change is a bit larger for the implicit no-cursor reaches. The rates of change are relative to asymptote (also customary is the rotation itself) which means that the same absolute change in reach direction given two very different rotations could result in the same relative change. To illustrate what is going on, we plot the exponential fits in real degrees, rather than relative percentages (and show the group average absolute change in the first trial in in the table, as determined by the exponential fit on the whole dataset: much less noisy than just averaging over the first trial), but to allow comparisons with previous papers (like [Ruttle et al., 2021](https://doi.org/10.1038/s41598-021-81031-y) and [Ruttle et al., 2022](https://doi.org/10.1152/jn.00082.2022) as well as many studies from other labs) we do the statistics on the relative _"rate of change"_.

In the table we can see that for total adaptation, the asymptotes increase with rotation size (as expected), but conversely, the relative learning rates go down. This would make sense if either 1) the brain does not actually use some learning rate, but a maximum amount of change for any giving error, or 2) if there is some source attribution process involved. For (implicit) no-cursor reaches the asymptote also goes up, but the learning rates are comparable for the two lower rotations and the two larger rotations, which indicates that the no-cursor reaches measure a different part of adaptation.

The washout periods otoh show the same pattern for both regular reaches and no-cursor reaches. In the 3 largest rotations, there seems a significant portion of labile implicit adaptation. Starting with the first aligned trial in the washout phase, the 3 larger rotations appear indistinguishable from each other. The 15 degree rotation shows smaller reach deviations in both types of trials, which signifies a qualitative difference between this small rotation and the 3 larger ones.

When looking at the relationship between explicit (re-aiming) and implicit (no-cursors), additivity of implicit and explicit adaptation would predict that as explicit adaptation goes up by some amount, implicit adaptation would have to go down by the same amount. That is, there should be a strong linear relationship with slope equal to -1. And while we think both processes contribute, they are not linearly additive. Additionally, the distribution of our measures of implicit shows the same peak for the 3 larger conditions, and a smaller one for the smallest rotation; the same pattern as in the no-cursor no-cursor washouts. For explicit re-aiming strategies, we see uni-modal distributions just above zero for the two smaller rotations, and bi-modal distributions for the two larger rotations, with 1 peak around zero and another peak at around 20 degrees. Maybe there is even a 3rd peak at 45 degrees for the largest rotation.

## Statistics

We wanted to do Bayesian statistics on functions fit to data for individual participants (functions are still in the GitHub repo). However, fits on individual fits regularly don't seem to work without additional coaxing: the asymptote would be the largest value allowed, and the learning rate exceptionally low. This makes statistics unreliable. We could remove all those participants, but this seems like an arbitrary approach. However, group fits, including bootstrapped fits, don't have this issue. So, while we loose the ability to make conclusions about equivalence, we are doing our stats with bootstrapped parameters.

For each parameter within each group we have 5k bootstrapped values. We can subtract one from the other and then get a 95% confidence interval of the difference. If that interval includes 0, we will conclude there is no difference, if the interval does not include 0, we will conclude there is a difference.

First we look at reach-training trials in exp 1, during the longer learning phase. For the learning phase we compare pairs of successive rotation sizes:

```{r}
expCIdiffs(exp=1, type='reaches', mode='learning')
```

Rates of change are not different, but asymptotes increase with rotation size.

No-cursors:

```{r}
expCIdiffs(exp=1, type='nocursors', mode='learning')
```
The 30 degrees group changes their no-cursor reach directions faster than the 45 degree group, as is also seen in the table. Otherwise there are no differences in learning rates in the comparisons here.

Asymptotes increase up to the 45 degrees at least.

Now we look at reach training trials during washout. For washout we compare the 15 degree group with all other groups.

```{r}
expCIdiffs(exp=1, type='reaches', mode='washout')
```
Rates of change are not different between 15 degrees and all other groups. But the 15 degree group has a smaller starting point.

And no-cursors:

```{r}
expCIdiffs(exp=1, type='nocursors', mode='washout')
```

For no-cursors we also see that the rate of change is the same in the 15 degree group as in all other groups, but the 15 degree group has a lower starting point than all other groups.

### Aiming

We have complemented the continuous measures of implicit reach aftereffects with 8 re-aiming trials after 56 trials of rotated training. Each set of 4 training and 4 no-cursor trials is preceded by a single re-aiming task, where people orient an arrow to indicate where they would move their hand in order to get the cursor on the target. The re-aiming trials are timed such that aiming does not affect the normal adaptation processes, as we have seen before ('t Hart et al., 2023, [bioRxiv](https://www.biorxiv.org/content/10.1101/2022.06.07.495044v3)). We expect little explicit strategy in the 15 and 30 degree conditions, and will see how this develops in larger rotations. Finally, we will also test if implicit adaptation can be predicted from explicit adaptation.

For those more interested in explicit adaptation; in the last experiment here we compare a continuous aiming condition with a control condition.

First we test if there is any effect of condition / rotation size on the magnitude of re-aiming responses:

```{r}
aimingBayesianFtest(exp=1)
```

There is, so that we now first compare the re-aiming responses to 0 for each condition, and then compare them between successive rotations.

Here are the comparisons with 0:

```{r}
aimingZero()
```

The evidence goes to some amount of re-aiming in the 15 degree condition (2.3 degrees) and in the 30 degree condition (3.9 degrees on average). In the other two conditions, it is much more clear that almost all participants engage in some amount of re-aiming. This can also be seen in Fig 2E.

Now we compare aiming between successive rotations.

```{r}
aimingGroupTtest(exp=1)
```

Re-aiming is not very different between the 15 and 30 degree groups, nor is it clearly the same. We do see the expected difference between the 30 and 45 degree group, but there is no evidence one way or another when comparing the 45 and 60 degree group. Perhaps both non-differences can be explained by the larger spread with larger rotations?

### Linear prediction of measures of implicit from measures of explicit adaptation

Here we test explicit adaptation as a predictor of implicit adaptation. We expect there to be some relationship in some cases. We have already shown that that relationship is not additive. Support for additivity would be obtained if there is a relationship with a slope of -1. We would say the slope is indistinguishable from -1 if the 95% confidence interval for the slope includes -1.

```{r}
testGroupLinearAdditivity(exp=1)
```

The slope is around -1 in the 15 degree group (with a very wide confidence interval, also including +1), but the linear relationship is not significant. For the 45 and 60 degree groups, the linear relationship _is_ significant, but the confidence interval for the slope does not include -1. So there is a weak, and non-additive relationship between implicit and explicit adaptation.

## Summary

The interleaved trial method we used in previous studies works pretty well here too. The explicit re-aiming trials also behave more or less as expected. Here is an overview of findings.

1. Rates of change do not increases between pairs of successive rotation sizes, except for no-cursors between the 30 and 45 degree group. There might be some qualitative difference between the two lower rotations and the two higher rotations (perhaps mirrored in the aiming extent).

2. Reach training asymptotes keep increasing with rotation size, which is not surprising. In no-cursor reach deviations the asymptote increases with rotation size, except between 45 and 60 degrees. It could be that implicit adaptation hits a maximum somewhere between 30 and 45 degrees of rotated feedback (but see the next point).

3. In washout, there is no effect of rotation size on "un-learning rates" but the starting point for the 15 degree group is lower than the starting point for all other groups. So, in contrast to the previous point it could also be that there is some maximum to implicit adaptation between 15 and 30 degrees of rotation. Perhaps one indicates "labile" and the other "stable" implicit adaptation?

4. There is some amount of re-aiming in all groups, although it is very low in the 15 and 30 degree conditions. Re-aiming strategies are not different (data doesn't provide evidence one way or another) between 15 and 30 degrees, and between 45 and 60 degrees. The latter perhaps due to large spread within each group, and possibly multi-modal distributions.

5. The extent of explicit strategies is at best a weak predictor of implicit adaptation.

To test how different kinds of feedback impact the time course of implicit adaptation - in particular in the presence of explicit adaptation as well, we will continue using the 45 degree rotation. It's an easier rotation to learn than the 60 degree rotation, but there is still sufficient implicit and explicit adaptation to modulate either of them up or down. We will skip the washout phases however, as they don't seem to add much to other measures. This also leaves time for additional measures.

# Experiment 2: feedback types

Here we test the time course of implicit adaptation, with two different kinds of feedback. In the rotation size experiment, the cursor was visible continuously, and was rotated right from the start of each trial. Here, in one condition, we keep the cursor aligned the first 50% of the reach, and introduce the rotation only after 50% of the home-target distance is exceeded. At that point, the cursor jumps from aligned to 45 degrees rotated: the _"cursor-jump"_ condition (cf. [Gastrock et al., 2020](https://doi.org/10.1038/s41598-020-76940-3)). Then, we also introduce a condition where the cursor is not shown during the reach, or during the return. It is only shown at 1 point: the first point that is at or beyond the distance of the target. The feedback is shown for 750 ms. We call this the _"terminal"_ condition.

Both are supposed to increase explicit learning, and should or could reduce implicit learning. We've observed both for the _cursor-jump_ condition ([Gastrock et al., 2020](https://doi.org/10.1038/s41598-020-76940-3)). While this has been shown before, but the time-course of implicit learning has not been characterized yet (but see [Ruttle et al., 2022](https://doi.org/10.1152/jn.00082.2022) for a first look at the effect of terminal feedback on the timecourse of another implicit process: proprioceptive recalibration). Apart from these 2 new conditions, we collect more participants doing a 45 degree rotation (albeit without the washout) and we combine these participants with the existing 45 degree as a reference condition for all new experiments, and we call this the _"control"_ condition.

Here is a table about the sample of participants:

```{r}
knitr::kable(demographicsTable(exp=2))
```

Here is the data:

```{r fig.width=6, fig.height=7.5}
expBehaviorFig(exp=2, target='inline', timecoursemode = 'absolute')
```

The table below is similar to that for experiment 1, except that there are no washout phases.

```{r}
knitr::kable(expTable(exp=2))
```

## Impressions from figure and table

Overall adaptation seems equal for the three groups. The control group does appear to have larger implicit aftereffects. The timecourses don't show much of a difference between the groups for overall adaptation. However, at first glance, the implicit, no-cursor timecourses do look qualitatively different. Implicit adaptation seems slower for cursor-jump and more so for terminal feedback, and they appear to have lower extent.

The distribution of explicit (re-aiming) strategies, appears to have more of a single solid peak, suggest that nearly all participants show some explicit strategy. That means they indeed evoked explicit adaptation to a much larger degree than the control condition.

Finally, there appears to be no clear relationship between these measures of implicit and explicit components of adaptation.

## Statistics

We first compare each test group with the control group on parameters describing overall adaptation:

```{r}
expCIdiffs(exp=2, type='reaches')
```

There are no differences between either test group and the control group in rates of change or asymptote for the overall adaptation, which matches the impression from the figure and table.

No we compare the test groups with the control group on parameters describing the timecourse of implicit reach aftereffects:

```{r}
expCIdiffs(exp=2, type='nocursors')
```

There is no effect on rates of change, but the asymptotic level of implicit reach aftereffects is larger for the control group than for either test group.

### Aiming

Testing for an effect of condition / group on re-aiming:

```{r}
aimingBayesianFtest(exp=2)
```

Seems there is an effect on explicit strategies, so now we compare the control group to the others:

```{r}
aimingGroupTtest(exp=2)
```

Both groups are different from control, and we can see in the table and figure that the terminal group and cursor-jump group have ~170% the amount of explicit strategy as compared to the control group (~14 vs. ~25 degrees of strategy).

### Linear prediction of implicit from explicit

Here we test explicit adaptation as a predictor of implicit adaptation.

```{r}
testGroupLinearAdditivity(exp=2)
```

For the control group (including the 45 degree group from the first experiment) the relationship is significant, but the confidence interval for the slope does not include -1 (like before in exp 1: adding more participants did not change this).

None of the other relations are significant, and the confidence intervals of the slopes include 0 but not -1.

## Summary

1. The two new conditions: terminal feedback and cursor-jump, did have the expected effect of increased explicit strategies.

2. This went hand-in-hand with opposite changes in the asymptotic level of implicit adaptation, but no difference in the rates of change.

3. Asymptotes and rates of change for reach-training trials were not different between the groups.

4. There was no clear relationship between levels of implicit adaptation and levels of explicit adaptation across the conditions.

In this experiment we can see that some manipulations (types of feedback) may work very well to increase explicit strategies and simultaneously decrease the extent of implicit adaptation. This hints at an additive relationship, but we don't clearly see this in the figures and it is not borne out by the linear models.

# Experiment 3: delays with terminal feedback

The terminal feedback in the previous experiment should lead to "explicit-only" adaptation, if there is a delay after reach completion and before the feedback is shown. We test this in a variant on the previous "terminal" condition where the feedback is presented after a delay, the _"delay -> feedback"_ condition. This changes both the overall duration of the experiment, which could also change learning. So we controlled for this with a condition where the terminal feedback is shown first, and then there is a delay of the same duration. We call this the _"feedback -> delay"_ condition. In these two tasks, the delays (with no feedback on the screen at all) are 1200 ms and the terminal feedback is shown for 600 ms. In both cases, the participant is supposed to _hold_ at the endpoint of their reach, so there is a separate hold time of 1800 ms. If the hold is broken (a movement of more than 1 cm away from the end position) then participants have to move to any point at 10 cm distance from the home position and restart the hold period of 1.8 s.

Here is a table about the sample of participants:

```{r}
knitr::kable(demographicsTable(exp=3))
```

The data is shown here:


```{r fig.width=6, fig.height=7.5}
expBehaviorFig(exp=3, target='inline', timecoursemode = 'absolute')
```

A table with summary / descriptive statistics:

```{r}
knitr::kable(expTable(exp=3))
```

## First observations

In the two new conditions, overall adaptation is comparable in both speed and asymptote with the previous terminal condition, as well as the control condition.

The speed of implicit adaptation seems to be in between that of the previous terminal condition and the control condition.

In both conditions with delay there is a wide range of explicit re-aiming strategies, including a small peak around 0 strategy this time. The average aiming strategy might actually be a little lower in these conditions, rather than higher. Distributions of implicit adaptation are comparable in all 3 terminal feedback conditions: the presence of delays, or the order of feedback and delay do not seem to affect the asymptotic levels of implicit adaptation.

It might no longer be surprising there seems to be no clear relationship between explicit and implicit measures of adaptation.

## Statistics

From the previous experiment, we know there is an effect of terminal feedback on the asymptote of implicit reach aftereffects. In this experiment we ask if there are any additional effects of delays. Therefore, we compare the two new groups to the previous terminal group. (We could have left out the control group.)

```{r}
expCIdiffs(exp=3, type='reaches')
```

There are no effects on overall adaptation.

```{r}
expCIdiffs(exp=3, type='nocursors')
```

There is no effect of the added delays on the speed or asymptote of implicit adaptation either.

### Aiming

We see if there is any effect on aiming responses:

```{r}
aimingBayesianFtest(exp=3)
```

There is an effect. Slightly surprising? Let's see where the differences are.

```{r}
aimingGroupTtest(exp=3)
```

It appears that in the terminal feedback without any kind of delay, the re-aiming responses are larger than in the terminal -> delay group, whereas there is little evidence for a difference or equivalence between the terminal group and the delay -> terminal group. That is: adding a delay after the terminal feedback makes adaptation _less_ explicit.

We had expected the delay -> terminal group to have more explicit adaptation, but that did not show up.

Both of these results are unexpected (and should perhaps be ignored).

### Linear correlation between implicit and explicit adaptation

Here we test explicit adaptation as a predictor of implicit adaptation.

```{r}
testGroupLinearAdditivity(exp=3)
```

The two untested groups here (the two with delays) again show no linear relationship between implicit and explicit adaptation.

## Summary

In the previous experiment we saw that terminal feedback did increase explicit adaptation relative to control. How about adding delays?

1. Counter to previous papers, adding delays after, but not before, the terminal feedback decreased explicit re-aiming (instead of the expected increase) with no clear effect with delays before the terminal feedback. Since this was not the topic we're investigating here, we don't attach much meaning to this finding here, but it shows that delays do not automatically make adaptation more explicit. Perhaps they needed to be longer.

2. There were no effects on overall learning or implicit adaptation.

3. Implicit and explicit adaptation seem largely independent from each other in the two new condition.

# Experiment 4: continuous aiming

So far, we have only used 8 re-aiming trials when adaptation was relatively close to saturation. In this experiment, we want to see if adding a re-aiming trial before each and every training trial affects explicit adaptation, and perhaps implicit adaptation as well. So we added a condition where every reach training trial was preceded by a re-aiming assessment (arrow orienting). We call this the _"aiming"_ condition (or sometimes "continuous aiming" as opposed to the sparse aiming done in the other conditions). This group also did a no-cursor reach after every training trial.

Of course, the aiming takes time so the the interval between training trials is increased. Perhaps this condition should be compared to the terminal -> delay condition as well?

Here is a table about the sample of participants:

```{r}
knitr::kable(demographicsTable(exp=4))
```

Here is the data:

```{r fig.width=6, fig.height=7.5}
expBehaviorFig(exp=4, target='inline', timecoursemode = 'absolute')
```
Here is the table with summary / descriptive statistics:

```{r}
knitr::kable(expTable(exp=4))
```

## First observations

The asymptote for the continuous aiming group looks a bit higher, at least at the start. We can see this in the exponential timecourse plots (fit on only the data up to where the first aiming is seen in most conditions: the 57th trial, but of course there has been a lot of aiming trials in the new condition at that point). At the end of the 100 trials of adaptation, levels seem more similar again, but it might just be that having to think about strategies in terms of directions of hand movements, gives away information to participants on the nature of the perturbation, and perhaps how to deal with it - acting as a partial instruction on how to counter the rotation. The no-cursor timecourse is similar in the continuous aiming group and the control group. The timecourse of explicit adaptation rises a bit faster though. The level of implicit adaptation in the new continuous adaptation group seems uni-modal, aligning with the first component in the distribution of implicit adaptation in the control group, so that it's overall slightly smaller. The distribution of explicit adaptation also looks uni-modal, but the average is ~170% of that in the control group. That is; adding continuous aiming increased the average strategy just as much as the cursorjump or terminal feedback did.

This is reminiscent of one of our earlier studies ('t Hart et al., under review). Compared to a 30 degree rotations, such as used there, the shift in average aiming strategy is larger here. On the other hand, with a 30 degree rotation, participants in a control condition seem not to have ay strategy, and adding continuous aiming to the same task now evokes a strategy, while here a large proportion of participants in the 45 degree rotation control already seemed to have a strategy. It could be that the data can still be explained as having 2 groups of participants, leading to what looks like a bi-modal distribution of strategies (I'm not adding any analyses here, can do later if wanted). One group would hover around no strategy, and the second group is spread out around some optimal strategy for dealing with a 45 degree rotation. Under continuous aiming, more people switch from the no-strategy sub-group to the strategy sub-group.

In this case, the added aiming even benefits overall adaptation - which we didn't see in the study using a smaller rotation.

## Statistics

```{r}
expCIdiffs(exp=4, type='reaches')
```

Continuous aiming seems to increase the asymptote of overall adaptation, but not the speed. The increased asymptote can also be seen in the figure.

```{r}
expCIdiffs(exp=4, type='nocursors')
```

Continuous aiming does not affect the time course of implicit reach aftereffects.

Using the same approach (and underlying functions), we can also see if implicit adaptation is slower than explicit adaptation. This is a bit of hacky use of the existing functions. In the results, the parameters for aiming (explicit) are always compared with parameters for no-cursors. But, while the aiming response timecourse always comes from the continuous aiming group, the no-cursor timecourse can be used from either the control group, or from the (continuous) aiming group. So when the results mentions 'control' the comparison is between groups, and when it doesn't it's within the aiming group.

We're really only interested in the rate of change, so no tests on the extent / asymptote / N0 are done.

```{r}
expCIdiffs(exp=4, type='aiming')
```

Regardless, with the current data set and approach, we can not detect a difference in how quickly implicit or explicit adaptation emerge. They might be equally fast in this group / these groups.

### Aiming

Let's see if there is a difference in aiming between the continuous aiming group and the control group.

```{r}
aimingGroupTtest(exp=4)
```

Here we see no difference in explicit strategy between groups of participants that only do aiming trials 8 times, and those that do aiming trials throughout the whole experiment. This contrasts with the 95% confidence intervals in the table, that don't even overlap.

### Implicit-explicit correlation

Here we test explicit adaptation as a predictor of implicit adaptation.

```{r}
testGroupLinearAdditivity(exp=4)
```

Also in the aiming group, there seems to be a significant, but non-additive (weak?) relationship between measures of implicit and measures of explicit adaptation.

## Summary

1. Adding continuous aiming increases the extent of overall adaptation, but seems to have no other effects here.

2. Continuously asking for re-aiming responses does not lead to a relationship between implicit and explicit adaptation.

3. We can not detect a difference in the speed of implicit and speed of explicit adaptation here, despite relatively high N (control:51, aiming:37).

This contrasts a bit with our earlier findings comparing (uninstructed) control with a continuous aiming group, where aiming increased explicit strategies (but had no other effects). Perhaps a 45 degree rotation is sufficient to evoke strategies by itself, and it doesn't require additional prodding such as continuous aiming or instructions about the perturbation (cf. [Modchalingam et al., 2019](https://doi.org/10.1371/journal.pone.0220884)).

# Conclusions

First, here we have a summary plot with (almost) all important data from all four experiments.

```{r fig.width=4, fig.height=8}
discussionPlot()
```


1. Using interleaved no-cursor trials we can gauge if implicit adaptation is 1) a slow process in adaptation, 2) affected by rotation size, 3) modulated by conditions that (mostly) increase explicit adaptation, and 4) linearly additive with explicit adaptation. The method works.

2. Increasing rotation size has the expected effects, validating this method.

3. Cursor-jump feedback and terminal feedback (without or without delays) mostly increase explicit adaptation and decrease implicit adaptation. The speed of implicit adaptation is not affected though.

4. In a condition with continuous aiming reports, we also see no effect on implicit adaptation and we can see that implicit and explicit adaptation develop at indistinguishable speeds.

Therefore: implicit adaptation seems pretty fast here, as well as mostly independent from explicit adaptation.

# Export manuscript figures

```{r eval=F}
targets <- c('pdf', 'svg', 'png', 'tiff') # c('pdf', 'svg', 'png', 'tiff')
for (exp in c(1:4)) {
  for (target in targets) {
    expBehaviorFig(exp=exp, target=target)
  }
}
for (target in targets) { discussionPlot(target=target) }
```

